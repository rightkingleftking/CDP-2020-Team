[INFO] loading images from the dataset...
[INFO] compiling model...
[INFO] training model...
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to
  ['...']
Train for 32 steps, validate on 1031 samples
Epoch 1/40
32/32 [==============================] - 788s 25s/step - loss: 0.3642 - accuracy: 0.8673 - val_loss: 0.1513 - val_accuracy: 0.9443
Epoch 2/40
32/32 [==============================] - 722s 23s/step - loss: 0.1161 - accuracy: 0.9564 - val_loss: 0.2755 - val_accuracy: 0.9258
Epoch 3/40
32/32 [==============================] - 654s 20s/step - loss: 0.0838 - accuracy: 0.9727 - val_loss: 0.1351 - val_accuracy: 0.9580
Epoch 4/40
32/32 [==============================] - 803s 25s/step - loss: 0.0714 - accuracy: 0.9715 - val_loss: 0.1854 - val_accuracy: 0.9502
Epoch 5/40
32/32 [==============================] - 767s 24s/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.1762 - val_accuracy: 0.9551
Epoch 6/40
32/32 [==============================] - 794s 25s/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.1543 - val_accuracy: 0.9570
Epoch 7/40
32/32 [==============================] - 736s 23s/step - loss: 0.0412 - accuracy: 0.9857 - val_loss: 0.1192 - val_accuracy: 0.9600
Epoch 8/40
32/32 [==============================] - 692s 22s/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.1612 - val_accuracy: 0.9541
Epoch 9/40
32/32 [==============================] - 852s 27s/step - loss: 0.0398 - accuracy: 0.9857 - val_loss: 0.1600 - val_accuracy: 0.9580
Epoch 10/40
32/32 [==============================] - 877s 27s/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.2007 - val_accuracy: 0.9551
Epoch 11/40
32/32 [==============================] - 998s 31s/step - loss: 0.0353 - accuracy: 0.9872 - val_loss: 0.1558 - val_accuracy: 0.9580
Epoch 12/40
32/32 [==============================] - 968s 30s/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.1227 - val_accuracy: 0.9668
Epoch 00012: early stopping
[INFO] evaluating network...
              precision    recall  f1-score   support
   with_mask       0.99      0.94      0.97       514
without_mask       0.94      0.99      0.97       517
    accuracy                           0.97      1031
   macro avg       0.97      0.97      0.97      1031
weighted avg       0.97      0.97      0.97      1031
[INFO] saving mask detector model...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
['Without Mask']
Traceback (most recent call last):
  File "C:\Users\chs65\OneDrive\Desktop\Training_model_zipped\train_mask_detector.py", line 218, in <module>
    plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")
  File "C:\Users\chs65\anaconda3\envs\env_tf\lib\site-packages\matplotlib\pyplot.py", line 2826, in plot
    **({"data": data} if data is not None else {}), **kwargs)
  File "C:\Users\chs65\anaconda3\envs\env_tf\lib\site-packages\matplotlib\axes\_axes.py", line 1743, in plot
    lines = [*self._get_lines(*args, data=data, **kwargs)]
  File "C:\Users\chs65\anaconda3\envs\env_tf\lib\site-packages\matplotlib\axes\_base.py", line 273, in __call__
    yield from self._plot_args(this, kwargs)
  File "C:\Users\chs65\anaconda3\envs\env_tf\lib\site-packages\matplotlib\axes\_base.py", line 399, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (40,) and (12,)
